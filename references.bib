
@inproceedings{suresh_framework_2021,
	address = {New York, NY, USA},
	series = {{EAAMO} '21},
	title = {A {Framework} for {Understanding} {Sources} of {Harm} throughout the {Machine} {Learning} {Life} {Cycle}},
	isbn = {978-1-4503-8553-4},
	url = {https://dl.acm.org/doi/10.1145/3465416.3483305},
	doi = {10.1145/3465416.3483305},
	abstract = {As machine learning (ML) increasingly affects people and society, awareness of its potential unwanted consequences has also grown. To anticipate, prevent, and mitigate undesirable downstream consequences, it is critical that we understand when and how harm might be introduced throughout the ML life cycle. In this paper, we provide a framework that identifies seven distinct potential sources of downstream harm in machine learning, spanning data collection, development, and deployment. In doing so, we aim to facilitate more productive and precise communication around these issues, as well as more direct, application-grounded ways to mitigate them.},
	urldate = {2025-06-17},
	booktitle = {Proceedings of the 1st {ACM} {Conference} on {Equity} and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Suresh, Harini and Guttag, John},
	month = nov,
	year = {2021},
	pages = {1--9},
}

@misc{czmiel_generative_2024,
	title = {Generative {KI}, {LLMs} und {GPT} bei digitalen {Editionen}},
	url = {https://doi.org/10.5281/zenodo.10698210},
	publisher = {Zenodo},
	author = {Czmiel, Alexander and Dumont, Stefan and Fischer, Franz and Pollin, Christopher and Sahle, Patrick and Schaßan, Torsten and Scholger, Martina and Vogeler, Georg and Roeder, Torsten and Fritze, Christiane and Henny-Krahmer, Ulrike},
	month = feb,
	year = {2024},
	doi = {10.5281/zenodo.10698210},
}

@article{mayr_data-efficient_2025,
	title = {Data-efficient handwritten text recognition of diplomatic historical text},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-024-20545-9},
	doi = {10.1007/s11042-024-20545-9},
	abstract = {Traditional methods in handwritten text recognition primarily focus on generating basic transcriptions, which often fall short for in-depth humanities research. Our study enhances this by providing diplomatic transcriptions for German studies, meticulously reproducing the original manuscripts, including layout and expanded abbreviations. State-of-the-art sequence-to-sequence approaches for handwritten text recognition predominantly use Connectionist Temporal Classification (CTC) as an auxiliary loss of the encoder output to improve robustness and accuracy. This is not possible in this task due to the great differences in the length of diplomatic transcriptions. We propose using the basic transcription instead of the diplomatic one as an additional target for the CTC feedback. Additionally, we introduce positional encoding at the intersection between the encoder and decoder to resolve the conflict of competing encoder objectives, balancing CTC loss reduction with the maintenance of implicit positional encoding for the decoder. Our empirical tests on the newly created dataset “Nuremberg Letterbooks” demonstrate significant data efficiency improvements. With only 4000 training lines (about 130 transcribed pages), we achieve a Character Error Rate (CER) of 9.39\% without expanded abbreviations and 12.07\% with expanded abbreviations, outperforming the baseline errors of 14.26\% and 68.21\%, respectively.},
	language = {en},
	urldate = {2025-06-06},
	journal = {Multimedia Tools and Applications},
	author = {Mayr, Martin and Neumeier, Katharina and Krenz, Julian and Bürcky, Simon and Kordon, Florian and Seuret, Mathias and Zöllner, Jochen and Wu, Fei and Maier, Andreas and Christlein, Vincent},
	month = jan,
	year = {2025},
	keywords = {Automated Pattern Recognition, Diplomatic transcriptions, ESCRT, Gene Transcription, Handwritten text recognition, Historical document analysis, Interspersed repetitive sequences, Orthography, Sample efficiency, Sequence Annotation, Transformers},
}

@article{birr_digitale_2024,
	title = {Das digitale {Nadelöhr}: {Die} {Arbeit} an einer digitalen {Edition} im {Projekt} „{Die} {Schule} von {Salamanca} “},
	journal = {Legal History Insights},
	author = {Birr, Christiane and Duve, Thomas},
	year = {2024},
}

@incollection{jannidis_digitale_2017,
	title = {Digitale {Editionen}},
	isbn = {978-3-476-02622-4},
	url = {https://doi.org/10.1007/978-3-476-05446-3},
	booktitle = {Digital {Humanities}. {Eine} {Einführung}.},
	publisher = {J.B. Metzler Stuttgart},
	author = {Sahle, Patrick},
	editor = {Jannidis, Fotis and Kohle, Hubertus and Rehbein, Malte},
	year = {2017},
	doi = {10.1007/978-3-476-05446-3},
}

@incollection{sahle_what_2016,
	address = {Cambridge},
	series = {Digital {Humanities} {Series}},
	title = {What is a {Scholarly} {Digital} {Edition}?},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	isbn = {9782821884007},
	url = {https://books.openedition.org/obp/3397},
	language = {en},
	urldate = {2025-05-23},
	booktitle = {Digital {Scholarly} {Editing} : {Theories} and {Practices}},
	publisher = {Open Book Publishers},
	author = {Sahle, Patrick},
	editor = {Driscoll, Matthew James and Pierazzo, Elena},
	year = {2016},
	pages = {19--39},
}

@incollection{galka_normalisierung_2021,
	title = {Normalisierung},
	url = {https://www.digitale-edition.at/o:konde.146},
	urldate = {2025-05-26},
	booktitle = {{KONDE} {Weißbuch}},
	author = {Galka, Selina},
	year = {2021},
	note = {Hrsg. v. Helmut W. Klug unter Mitarbeit von Selina Galka und Elisabeth Steiner im HRSM Projekt "Kompetenznetzwerk Digitale Edition"},
}

@incollection{klug_transkription_2021,
	title = {Transkription},
	url = {https://www.digitale-edition.at/o:konde.197},
	urldate = {2025-05-26},
	booktitle = {{KONDE} {Weißbuch}},
	author = {Klug, Helmut W.},
	year = {2021},
	note = {Hrsg. v. Helmut W. Klug unter Mitarbeit von Selina Galka und Elisabeth Steiner im HRSM Projekt "Kompetenznetzwerk Digitale Edition"},
}

@incollection{cugliana_diplomatische_2024,
	title = {Diplomatische {Transkription}},
	url = {https://www.digitale-edition.at/o:konde.65},
	urldate = {2025-05-26},
	booktitle = {{KONDE} {Weißbuch}},
	author = {Cugliana, Elisa and Gengnagel, Tessa},
	year = {2024},
	note = {Hrsg. v. Helmut W. Klug unter Mitarbeit von Selina Galka und Elisabeth Steiner im HRSM Projekt "Kompetenznetzwerk Digitale Edition"},
}

@article{fritze_wohin_2019,
	title = {Wohin mit der digitalen {Edition}?: {Ein} {Beitrag} aus der {Perspektive} der Österreichischen {Nationalbibliothek}},
	volume = {43},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	issn = {1865-7648},
	shorttitle = {Wohin mit der digitalen {Edition}?},
	url = {https://www.degruyterbrill.com/document/doi/10.1515/bfp-2019-2068/html},
	doi = {10.1515/bfp-2019-2068},
	abstract = {Zusammenfassung Editionen bieten verschiedenen geisteswissenschaftlichen Fächern die Grundlage für weitere Forschungen. Mit der Digitalisierung erleben die Editionswissenschaften zunehmend projektbasiert und drittmittelgefördert eine Renaissance. Problematisch bleibt die Frage, wohin mit der Edition nach Projektende? Schon von Beginn an sollten Bibliotheken mit den ihnen eigenen Services und Kompetenzen ernstzunehmende Partner sein, müssten sich allerdings der Aufgabe v. a. in finanzieller Hinsicht stellen.},
	language = {de},
	number = {3},
	urldate = {2025-05-26},
	journal = {Bibliothek Forschung und Praxis},
	author = {Fritze, Christiane},
	month = dec,
	year = {2019},
	keywords = {Austrian National Library, Scholarly digital edition, long term availability, sustainability},
	pages = {432--440},
}

@book{jannidis_digital_2017,
	title = {Digital {Humanities}. {Eine} {Einführung}.},
	isbn = {978-3-476-02622-4},
	url = {https://doi.org/10.1007/978-3-476-05446-3},
	publisher = {J.B. Metzler Stuttgart},
	author = {Jannidis, Fotis and Kohle, Hubertus and Rehbein, Malte},
	year = {2017},
	doi = {10.1007/978-3-476-05446-3},
}

@article{janiesch_machine_2021,
	title = {Machine learning and deep learning},
	volume = {31},
	issn = {1422-8890},
	url = {https://doi.org/10.1007/s12525-021-00475-2},
	doi = {10.1007/s12525-021-00475-2},
	abstract = {Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization.},
	number = {3},
	journal = {Electronic Markets},
	author = {Janiesch, Christian and Zschech, Patrick and Heinrich, Kai},
	month = sep,
	year = {2021},
	pages = {685--695},
}

@book{sarkar_practical_2018,
	title = {Practical {Machine} {Learning} with {Python}},
	isbn = {978-1-4842-3207-1},
	publisher = {Apress},
	author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
	year = {2018},
	doi = {10.1007/978-1-4842-3207-1},
}

@article{li_survey_2022,
	title = {A {Survey} on {Deep} {Learning} for {Named} {Entity} {Recognition}},
	volume = {34},
	doi = {10.1109/TKDE.2020.2981314},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Li, Jing and Sun, Aixin and Han, Jianglei and Li, Chenliang},
	year = {2022},
	keywords = {Annotations, Deep learning, Encyclopedias, Natural language processing, Task analysis, Text recognition, Tools, deep learning, named entity recognition, survey},
	pages = {50--70},
}

@book{buck_wissenschaftliches_2025,
	address = {Konstanz},
	edition = {1},
	series = {Studieren, aber richtig},
	title = {Wissenschaftliches {Schreiben} mit {KI}},
	isbn = {9783825263652},
	language = {German},
	publisher = {UVK Verlag},
	author = {Buck, Isabella},
	month = mar,
	year = {2025},
	doi = {10.36198/9783838563657},
}

@misc{oberbichler_working_2025,
	title = {Working {Paper}: {Implementing} {Generative} {AI} in the {Historical} {Studies}},
	url = {https://doi.org/10.5281/zenodo.14924737},
	publisher = {Zenodo},
	author = {Oberbichler, Sarah and Petz, Cindarella},
	month = feb,
	year = {2025},
	doi = {10.5281/zenodo.14924737},
}

@article{chang_survey_2024,
	title = {A {Survey} on {Evaluation} of {Large} {Language} {Models}},
	volume = {15},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3641289},
	doi = {10.1145/3641289},
	abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:},
	number = {3},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
	month = mar,
	year = {2024},
	keywords = {Large language models, benchmark, evaluation, model assessment},
}
